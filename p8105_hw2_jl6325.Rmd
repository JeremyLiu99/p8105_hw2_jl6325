---
title: "p8105_hw2_jl6325"
author: "Jianing Liu"
date: "2023-10-03"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(tidyverse)
library(readxl)
```
# problem 1
```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```
We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.
```{r clean_538_snp}
snp = 
  read_csv(
    "./data/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```
Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.
```{r clean_538_unemp}
unemployment = 
  read_csv("./data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```
Now we merge the three datasets!
```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```
Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

# Problem 2
Mr. Trash Wheel
```{r import_Mr}
Mr_Trash_Wheel <- read_excel("data/202309 Trash Wheel Collection Data.xlsx",
                         sheet = "Mr. Trash Wheel",
                         range = "A2:N586")|>
                         janitor::clean_names()|>
                           drop_na(dumpster)|>
                           mutate(homes_powered = weight_tons*500/30,
                                  name = "Mr. Trash Wheel",
                                  year = as.numeric(year))|>
                           select(everything())
```
Professor Trash Wheel
```{r import_Prof}
Professor_Trash_Wheel <- read_excel("data/202309 Trash Wheel Collection Data.xlsx",
                         sheet = "Professor Trash Wheel",
                         range = "A2:M108")|>
                         janitor::clean_names()|>
                           drop_na(dumpster)|>
                           mutate(homes_powered = weight_tons*500/30,
                                  name = "Professor Trash Wheel")|>
                           select(everything())
```
Gwynnda
```{r import_Gwynnda}
Gwynnda_Trash_Wheel <- read_excel("data/202309 Trash Wheel Collection Data.xlsx",
                         sheet = "Gwynnda Trash Wheel",
                         range = "A2:L157")|>
                         janitor::clean_names()|>
                           drop_na(dumpster)|>
                           mutate(homes_powered = weight_tons*500/30,
                                  name = "Gwynnda")|>
                           select(everything())
```
Combining all 3 datasets
```{r combine}
Trash_Wheel_Datasets <- 
              bind_rows(Mr_Trash_Wheel, Professor_Trash_Wheel, Gwynnda_Trash_Wheel)
```
There are 845 observations and 15 variables in the resulting dataset(Trash_Whell_Datasets),
and the variables are name(which trash wheel), month, year, weight_tons, and homes_powered by
codes nrow(Trash_Wheel_Datasets)
ncol(Trash_Wheel_Datasets).

The total weight of trash collected by Professor Trash Wheel is 216.26 tons by this code filter(Trash_Wheel_Datasets, name == "Professor Trash Wheel")|>
  pull(weight_tons)|>
  sum().

The total number of cigarette butts collected by Gwynnda in July of 2021 is 16300 by this code filter(Trash_Wheel_Datasets, name == "Gwynnda", year == 2021, month == "July")|>
  pull(cigarette_butts)|>
  sum().

# Problem 3
```{r}
MB = 
  read_csv("data/MCI_baseline.csv", skip = 1, na = c(".")) |>
  janitor::clean_names() |>
  mutate(sex = case_match(sex, 1 ~ "male", 0 ~ "female"),
         apoe4 = case_match(apoe4, 1 ~ "positive", 0 ~ "negative"),
         age_at_onset = as.numeric(age_at_onset))
MB
```

There were 483 participants at the start of the research.

```{r Baseline}
free_of_MCI = MB|>
  filter(age_at_onset - current_age > 0 | is.na(age_at_onset))

got_MCI = MB|>
  filter(age_at_onset - current_age > 0)

mean(pull(free_of_MCI, current_age))

nrow(filter(free_of_MCI, sex == "female" & apoe4 == "positive")) / nrow(filter(free_of_MCI, sex == "female"))
```
We first filter all the observations free of MCI at the start of this study,
then we find out 93 of them developed  to MCI,
and the average age is 65 years old,
and the proportion of women in the study are APOE4 carriers 30%.

```{r Amyloid}
MA = read_csv("data/mci_amyloid.csv",
              skip = 1)|>
  janitor::clean_names()|>
  rename(id = study_id)|>
  pivot_longer(baseline:time_8)
```
Import all the data and use pivot_longer to tidy data.

```{r combine_MCI}
basline = anti_join(free_of_MCI, MA, by = "id")
amyloid = anti_join(MA, free_of_MCI, by = "id")
combine_MCI = inner_join(free_of_MCI, MA, by = "id")
```
There are 8 participants are in baseline only,
there are 16 (80/5) participants are in amyloid only,
and there are 2355 observations matched with both baseline and amyloid,
and the number of participants are 2355/5 = 471.

```{r}
write.csv(combine_MCI, "combine_MCI.csv")
```